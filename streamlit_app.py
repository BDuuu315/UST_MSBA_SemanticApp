
import streamlit as st
import random
import os
import numpy as np
import pandas as pd
from openai import AzureOpenAI

# ========= é¡µé¢é…ç½® =========
st.set_page_config(
    page_title="Semantic Search AI Chat",
    layout="centered",
    initial_sidebar_state="expanded",
)

# ========= Logo æ ·å¼ =========
st.markdown(
    """
    <style>
    [data-testid="stAppViewContainer"] {
        position: relative;
    }
    .logo { 
        position: fixed;
        top: 10px;
        left: 15px;
        z-index: 100;
    }
    </style>
    """,
    unsafe_allow_html=True
)
st.image("Logo_USTBusinessSchool.svg", width=120, output_format="SVG")

# ========= åˆå§‹åŒ–çŠ¶æ€ =========
if "conversations" not in st.session_state:
    st.session_state["conversations"] = []  # æ¯ä¸ªå…ƒç´ ä¸º list[dict(role, content)]
if "conversation_titles" not in st.session_state:
    st.session_state["conversation_titles"] = []  # ä¿å­˜ä¼šè¯æ ‡é¢˜
if "active_chat_index" not in st.session_state:
    st.session_state["active_chat_index"] = None
if "OPENAI_API_KEY" not in st.session_state:
    st.session_state["OPENAI_API_KEY"] = None

# ========= åˆå§‹åŒ–Azure OpenAIå®¢æˆ·ç«¯ =========
@st.cache_resource
def get_azure_client(api_key):
    return AzureOpenAI(
        api_key=api_key,
        api_version="2023-05-15",
        azure_endpoint="https://hkust.azure-api.net"
    )


# ========= Sidebar =========
st.sidebar.title("Chat Sidebar")


# --- è¾“å…¥ API Key ---
api_key = st.sidebar.text_input(
    "Enter your HKUST OpenAI API Key",
    type="password",
    help="You can check ISOM 6670G syllabus to get set-up instructions."
)
if api_key:
    st.session_state["OPENAI_API_KEY"] = api_key

st.sidebar.markdown("---")

# --- æ–°å»ºä¼šè¯æŒ‰é’® ---
if st.sidebar.button("ğŸ†• New Chat", use_container_width=True):
    st.session_state["conversations"].append([])
    st.session_state["conversation_titles"].append("New Chat")
    st.session_state["active_chat_index"] = len(st.session_state["conversations"]) - 1

# --- æ¸…é™¤æ‰€æœ‰å†å²æŒ‰é’®  ---
if st.sidebar.button("ğŸ—‘ï¸ Clear All History", use_container_width=True):
    st.session_state["conversations"].clear()
    st.session_state["conversation_titles"].clear()
    st.session_state["active_chat_index"] = None
    st.rerun()

# --- å†å²åˆ—è¡¨ ---
st.sidebar.subheader("History")

if len(st.session_state["conversations"]) == 0:
    st.sidebar.info("No history yet. Click 'New Chat' to start.")
else:
    for i, title in enumerate(st.session_state["conversation_titles"]):
        max_length = 20
        if len(title) > max_length:
            display_title = title[:max_length] + "..."
        else:
            display_title = title

        if i == st.session_state["active_chat_index"]:
            st.sidebar.button(f"ğŸ“ {display_title}", key=f"chat_active_{i}", disabled=True, use_container_width=True)
        else:
            if st.sidebar.button(f"ğŸ’¬ {display_title}", key=f"chat_{i}", use_container_width=True):
                st.session_state["active_chat_index"] = i

# ========= ä¸»ä½“éƒ¨åˆ† =========
st.title("Semantic Search AI Chat for BA Users")
st.caption("A Semantic Search App prototype for ISOM 6670G.")

# --- è¾“å…¥æ–°æ¶ˆæ¯ ---
user_query = st.text_input(
    label="Enter your question:",
    placeholder="e.g., Where is HKUST Business School?",
    help="Type your natural language question here."
)

# ========= åˆå§‹åŒ–çŠ¶æ€ =========
if "conversations" not in st.session_state:
    st.session_state["conversations"] = []
if "conversation_titles" not in st.session_state:
    st.session_state["conversation_titles"] = []
if "active_chat_index" not in st.session_state:
    st.session_state["active_chat_index"] = None
if "OPENAI_API_KEY" not in st.session_state:
    st.session_state["OPENAI_API_KEY"] = None
if "documents" not in st.session_state:
    st.session_state["documents"] = [
        {"id": 1, "content": "HKUST Business School offers MBA programs with focus on analytics.", "embedding": None},
        {"id": 2, "content": "The ISOM department provides courses in information systems.", "embedding": None},
    ]
# --- æ²¡æœ‰æ¿€æ´»çš„èŠå¤©æ—¶æç¤º ---
if st.session_state["active_chat_index"] is None:
    st.info("Click *'New Chat'* in the sidebar to start a conversation.")
    st.stop()

# --- å·²é€‰å®šçš„ä¼šè¯ ---
chat_index = st.session_state["active_chat_index"]
current_chat = st.session_state["conversations"][chat_index]
chat_title = st.session_state["conversation_titles"][chat_index]

# --- å±•ç¤ºå·²æœ‰æ¶ˆæ¯ ---
for msg in current_chat:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])


if user_query:
    # è‹¥æ²¡æœ‰ API keyï¼Œä¸å…è®¸ç»§ç»­
    if not st.session_state.get("OPENAI_API_KEY"):
        st.error("Please input your HKUST OpenAI API key in the sidebar first.")
        st.stop()

    # 1ï¸âƒ£ ç«‹å³æ˜¾ç¤ºå¹¶ä¿å­˜ç”¨æˆ·è¾“å…¥
    st.chat_message("user").write(user_query)
    current_chat.append({"role": "user", "content": user_query})

    # è‹¥è¿™æ˜¯è¯¥ä¼šè¯ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼Œåˆ™ç”¨å®ƒæ›´æ–°æ ‡é¢˜
    if len(current_chat) == 1:
        st.session_state["conversation_titles"][chat_index] = user_query[:40]

    # 2ï¸âƒ£ ç”Ÿæˆembeddingå¹¶è·å–AIå›ç­”
    with st.spinner("Processing your query with semantic search..."):
        try:
            # åˆå§‹åŒ–Azure OpenAIå®¢æˆ·ç«¯
            openai_client = get_azure_client(st.session_state["OPENAI_API_KEY"])
            
            # ä¸ºæŸ¥è¯¢ç”Ÿæˆembedding
            response = openai_client.embeddings.create(
                input=user_query,
                model="text-embedding-ada-002"
            )
            
            # è·å–embeddingå‘é‡
            query_vector = response.data[0].embedding
            vector_dim = len(query_vector)
            
            # æ¨¡æ‹Ÿè¯­ä¹‰æœç´¢ç»“æœï¼ˆè¿™é‡Œå¯ä»¥æ›¿æ¢ä¸ºä½ çš„å®é™…æœç´¢é€»è¾‘ï¼‰
            # åŸºäºembeddingè¿›è¡Œç›¸ä¼¼åº¦æœç´¢ç­‰æ“ä½œ
            
            # ç”Ÿæˆå›ç­”
            simulated_answer = (
                f"Question has been processed with semantic search!\n\n"
                f"**Question:** {user_query}\n\n"
                f"**Embedding Dimension:** {vector_dim}\n"
            )
            confidence = round(random.uniform(0.75, 0.99), 2)
            answer_text = f"{simulated_answer}\n\n**Confidence Score:** {confidence}"
            
        except Exception as e:
            answer_text = f"Error processing your query: {str(e)}\n\nPlease check your API key and try again."
            confidence = 0.0

    # 3ï¸âƒ£ æ˜¾ç¤º AI å›å¤å¹¶ä¿å­˜
    st.chat_message("assistant").write(answer_text)
    current_chat.append({"role": "assistant", "content": answer_text})

# ========= æ˜¾ç¤ºembeddingä¿¡æ¯ =========
with st.expander("ğŸ” Embedding Information"):
    st.markdown("""
    **How Semantic Search Works:**
    - Convert question into a numerical vector (embedding)
    - Capture semantic meaning
    - Calculate similarity between question and document embeddings
    - Most relevant documents are returned based on semantic similarity
    """)
    
    if 'query_vector' in locals():
        st.metric("Embedding Dimension", vector_dim)
        st.write("First 10 embedding values:")
        st.code(str(query_vector[:10]))
