
import streamlit as st
import random
import os
import numpy as np
import pandas as pd
from openai import AzureOpenAI

# ========= é¡µé¢é…ç½® =========
st.set_page_config(
    page_title="Semantic Search AI Chat",
    layout="centered",
    initial_sidebar_state="expanded",
)

# ========= Logo æ ·å¼ =========
st.markdown(
    """
    <style>
    [data-testid="stAppViewContainer"] {
        position: relative;
    }
    .logo { 
        position: fixed;
        top: 10px;
        left: 15px;
        z-index: 100;
    }
    </style>
    """,
    unsafe_allow_html=True
)
st.image("Logo_USTBusinessSchool.svg", width=120, output_format="SVG")

# ========= åˆå§‹åŒ–çŠ¶æ€ =========
if "conversations" not in st.session_state:
    st.session_state["conversations"] = []  # æ¯ä¸ªå…ƒç´ ä¸º list[dict(role, content)]
if "conversation_titles" not in st.session_state:
    st.session_state["conversation_titles"] = []  # ä¿å­˜ä¼šè¯æ ‡é¢˜
if "active_chat_index" not in st.session_state:
    st.session_state["active_chat_index"] = None
if "OPENAI_API_KEY" not in st.session_state:
    st.session_state["OPENAI_API_KEY"] = None

# ========= åˆå§‹åŒ–Azure OpenAIå®¢æˆ·ç«¯ =========
@st.cache_resource
def get_azure_client(api_key):
    return AzureOpenAI(
        api_key=api_key,
        api_version="2023-05-15",
        azure_endpoint="https://hkust.azure-api.net"
    )


    """æ¸²æŸ“ç”¨æˆ·è¾“å…¥ç•Œé¢"""
    st.sidebar.title("ğŸ§  App Settings")

    # --- Keys ---
    openai_key = st.sidebar.text_input("Enter your HKUST Azure OpenAI Key:", type="password")
    pinecone_key = st.sidebar.text_input("Enter your Pinecone API Key:", type="password")
    if openai_key:
        st.session_state["OPENAI_API_KEY"] = openai_key
    if pinecone_key:
        st.session_state["PINECONE_API_KEY"] = pinecone_key

    st.sidebar.divider()

    # --- New Chat / Clear All ---
    if st.sidebar.button("ğŸ†• New Chat", use_container_width=True):
        st.session_state["conversations"].append([])
        st.session_state["conversation_titles"].append("New Chat")
        st.session_state["active_chat_index"] = len(st.session_state["conversations"]) - 1
    if st.sidebar.button("ğŸ—‘ï¸ Clear All Chats", use_container_width=True):
        st.session_state["conversations"].clear()
        st.session_state["conversation_titles"].clear()
        st.session_state["active_chat_index"] = None
        st.rerun()

    st.sidebar.subheader("ğŸ’¬ Chat History")
    if len(st.session_state["conversation_titles"]) == 0:
        st.sidebar.info("No history yet. Create a new chat to start.")
    else:
        for i, title in enumerate(st.session_state["conversation_titles"]):
            if i == st.session_state["active_chat_index"]:
                st.sidebar.button(f"ğŸ“ {title}", key=f"chat_{i}", disabled=True, use_container_width=True)
            else:
                if st.sidebar.button(f"ğŸ’¬ {title}", key=f"chat_{i}", use_container_width=True):
                    st.session_state["active_chat_index"] = i

    st.sidebar.divider()

    # ============================
    # ğŸ”Œ API Status + Config Section
    # ============================
    st.sidebar.header("ğŸ”§ API Status")
    col_a, col_b = st.sidebar.columns(2)
    with col_a: st.success("âœ… Pinecone: Connected")
    with col_b: st.success("âœ… Azure OpenAI: Connected")

    st.sidebar.header("âš™ï¸ Search Configuration")
    top_k = st.sidebar.slider("Number of documents to return", 1, 10, 3)

    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ’¡ Usage Tips")
    st.sidebar.info("""
    - Enter complete question statements  
    - More specific questions yield more accurate results  
    - Supports both Chinese and English queries  
    - System generates answers based on relevant documents
    """)

    # --- Test ConnectionæŒ‰é’® ---
    if st.sidebar.button("ğŸ”„ Test Connection", use_container_width=True):
        with st.spinner("Testing API connection..."):
            try:
                client = get_azure_client(st.session_state["OPENAI_API_KEY"])
                response = client.embeddings.create(input="Hello world", model="text-embedding-ada-002")
                st.sidebar.success("âœ… Azure OpenAI connection successful!")
            except Exception as e:
                st.sidebar.error(f"âŒ Connection failed: {e}")
    
    return top_k

# ========= ä¸»ä½“éƒ¨åˆ† =========
st.title("Semantic Search AI Chat for BA Users")
st.caption("A Semantic Search App prototype for ISOM 6670G.")

if len(st.session_state["conversations"]) == 0:
    st.session_state["conversations"].append([])
    st.session_state["conversation_titles"].append("New Chat")
    st.session_state["active_chat_index"] = 0
    st.rerun()

# --- è¾“å…¥æ–°æ¶ˆæ¯ ---
user_query = st.text_input(
    label="Enter your question:",
    placeholder="e.g., Where is HKUST Business School?",
    help="Type your natural language question here."
)

# ========= åˆå§‹åŒ–çŠ¶æ€ =========
if "conversations" not in st.session_state:
    st.session_state["conversations"] = []
if "conversation_titles" not in st.session_state:
    st.session_state["conversation_titles"] = []
if "active_chat_index" not in st.session_state:
    st.session_state["active_chat_index"] = None
if "OPENAI_API_KEY" not in st.session_state:
    st.session_state["OPENAI_API_KEY"] = None
if "documents" not in st.session_state:
    st.session_state["documents"] = [
        {"id": 1, "content": "HKUST Business School offers MBA programs with focus on analytics.", "embedding": None},
        {"id": 2, "content": "The ISOM department provides courses in information systems.", "embedding": None},
    ]
# --- æ²¡æœ‰æ¿€æ´»çš„èŠå¤©æ—¶æç¤º ---
if st.session_state["active_chat_index"] is None:
    st.info("Click *'New Chat'* in the sidebar to start a conversation.")
    st.stop()

# --- å·²é€‰å®šçš„ä¼šè¯ ---
chat_index = st.session_state["active_chat_index"]
current_chat = st.session_state["conversations"][chat_index]
chat_title = st.session_state["conversation_titles"][chat_index]

# --- å±•ç¤ºå·²æœ‰æ¶ˆæ¯ ---
for msg in current_chat:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])


if user_query:
    # è‹¥æ²¡æœ‰ API keyï¼Œä¸å…è®¸ç»§ç»­
    if not st.session_state.get("OPENAI_API_KEY"):
        st.error("Please input your HKUST OpenAI API key in the sidebar first.")
        st.stop()

    # 1ï¸âƒ£ ç«‹å³æ˜¾ç¤ºå¹¶ä¿å­˜ç”¨æˆ·è¾“å…¥
    st.chat_message("user").write(user_query)
    current_chat.append({"role": "user", "content": user_query})

    # è‹¥è¿™æ˜¯è¯¥ä¼šè¯ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼Œåˆ™ç”¨å®ƒæ›´æ–°æ ‡é¢˜
    if len(current_chat) == 1:
        st.session_state["conversation_titles"][chat_index] = user_query[:40]

    # 2ï¸âƒ£ ç”Ÿæˆembeddingå¹¶è·å–AIå›ç­”
    with st.spinner("Processing your query with semantic search..."):
        try:
            # åˆå§‹åŒ–Azure OpenAIå®¢æˆ·ç«¯
            openai_client = get_azure_client(st.session_state["OPENAI_API_KEY"])
            
            # ä¸ºæŸ¥è¯¢ç”Ÿæˆembedding
            response = openai_client.embeddings.create(
                input=user_query,
                model="text-embedding-ada-002"
            )
            
            # è·å–embeddingå‘é‡
            query_vector = response.data[0].embedding
            vector_dim = len(query_vector)
            
            # æ¨¡æ‹Ÿè¯­ä¹‰æœç´¢ç»“æœï¼ˆè¿™é‡Œå¯ä»¥æ›¿æ¢ä¸ºä½ çš„å®é™…æœç´¢é€»è¾‘ï¼‰
            # åŸºäºembeddingè¿›è¡Œç›¸ä¼¼åº¦æœç´¢ç­‰æ“ä½œ
            
            # ç”Ÿæˆå›ç­”
            simulated_answer = (
                f"Question has been processed with semantic search!\n\n"
                f"**Question:** {user_query}\n\n"
                f"**Embedding Dimension:** {vector_dim}\n"
            )
            confidence = round(random.uniform(0.75, 0.99), 2)
            answer_text = f"{simulated_answer}\n\n**Confidence Score:** {confidence}"
            
        except Exception as e:
            answer_text = f"Error processing your query: {str(e)}\n\nPlease check your API key and try again."
            confidence = 0.0

    # 3ï¸âƒ£ æ˜¾ç¤º AI å›å¤å¹¶ä¿å­˜
    st.chat_message("assistant").write(answer_text)
    current_chat.append({"role": "assistant", "content": answer_text})

# ========= æ˜¾ç¤ºembeddingä¿¡æ¯ =========
with st.expander("ğŸ” Embedding Information"):
    st.markdown("""
    **How Semantic Search Works:**
    - Convert question into a numerical vector (embedding)
    - Capture semantic meaning
    - Calculate similarity between question and document embeddings
    - Most relevant documents are returned based on semantic similarity
    """)
    
    if 'query_vector' in locals():
        st.metric("Embedding Dimension", vector_dim)
        st.write("First 10 embedding values:")
        st.code(str(query_vector[:10]))
