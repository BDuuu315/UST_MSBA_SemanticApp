import streamlit as st
import random
import numpy as np
from openai import AzureOpenAI
from pinecone import Pinecone

# ========= È°µÈù¢ÈÖçÁΩÆ =========
st.set_page_config(
    page_title="Semantic Search AI Chat (Pinecone RAG)",
    layout="centered",
    initial_sidebar_state="expanded",
)

# ========= Logo Ê†∑Âºè =========
st.markdown(
    """
    <style>
    [data-testid="stAppViewContainer"] {
        position: relative;
    }
    .logo { 
        position: fixed;
        top: 10px;
        left: 15px;
        z-index: 100;
    }
    section[data-testid="stSidebar"] {
        width: 380px !important;
        min-width: 380px !important;
        height: 100vh;
        overflow: auto;
    }
    section[data-testid="stSidebar"] > div {
        width: 380px !important;
        padding-top: 2rem;
        height: 100%;
    }
    .stSidebar .stButton>button {
        width: 100%;
    }
    .main .block-container {
        padding-left: 400px;
        padding-right: 2rem;
    }
    </style>
    """,
    unsafe_allow_html=True
)
st.image("Logo_USTBusinessSchool.svg", width=120, output_format="SVG")

# ========= Pinecone & Azure Config =========
PINECONE_API_KEY = "pcsk_JPQMS_zQZ9MfrD4aSEe8b69PoxsjcsvoSPEHpzgYGt4GPm8bv7ED95Wjy4u7vPmxSnjj"
PINECONE_INDEX_NAME = "msba-lab-1537"
PINECONE_NAMESPACE = "default"

# ========= ÂàùÂßãÂåñÁä∂ÊÄÅ =========
if "conversations" not in st.session_state:
    st.session_state["conversations"] = []
if "conversation_titles" not in st.session_state:
    st.session_state["conversation_titles"] = []
if "active_chat_index" not in st.session_state:
    st.session_state["active_chat_index"] = None
if "OPENAI_API_KEY" not in st.session_state:
    st.session_state["OPENAI_API_KEY"] = None
if "last_processed_query" not in st.session_state:
    st.session_state["last_processed_query"] = None

# ========= ÂàùÂßãÂåñÂÆ¢Êà∑Á´Ø =========
@st.cache_resource
def get_azure_client(api_key):
    if not api_key:
        return None
    return AzureOpenAI(
        api_key=api_key,
        api_version="2023-05-15",
        azure_endpoint="https://hkust.azure-api.net"
    )

@st.cache_resource
def get_pinecone_client():
    pc = Pinecone(api_key=PINECONE_API_KEY)
    return pc.Index(PINECONE_INDEX_NAME)

# ========= ËØ≠‰πâÊêúÁ¥¢ÂáΩÊï∞ (PineconeÊ£ÄÁ¥¢) =========
def semantic_search(query, client, top_k=5):
    """‰ΩøÁî® AzureOpenAI embedding + Pinecone ËøõË°åËØ≠‰πâÊêúÁ¥¢"""
    try:
        emb_resp = client.embeddings.create(
            input=query,
            model="text-embedding-ada-002"
        )
        query_vector = np.array(emb_resp.data[0].embedding)

        index = get_pinecone_client()
        search_resp = index.query(
            namespace=PINECONE_NAMESPACE,
            vector=query_vector.tolist(),
            top_k=top_k,
            include_metadata=True
        )

        matches = []
        for item in search_resp.matches:
            matches.append({
                "score": item.score,
                "text": item.metadata.get("text") or item.metadata.get("chunk_text") or "",
                "source": item.metadata.get("source", "N/A")
            })
        return matches, query_vector, len(query_vector)
    except Exception as e:
        st.error(f"Pinecone ÊêúÁ¥¢ÈîôËØØ: {e}")
        return [], None, 0

# ========= ÊûÑÂª∫Â¢ûÂº∫ Prompt =========
def build_augmented_prompt(user_query, search_results):
    """Ê†πÊçÆÊ£ÄÁ¥¢Âà∞ÁöÑ‰∏ä‰∏ãÊñáÊûÑÈÄ†Áªô GPT ÁöÑÂ¢ûÂº∫ÊèêÁ§∫ËØç"""
    context = "\n\n".join([f"[Source {i+1}] {r['text']}" for i, r in enumerate(search_results)])
    augmented_prompt = f"""
You are an assistant that answers questions based strictly on the given contextual documents.

**User Question:**
{user_query}

**Retrieved Context:**
{context}

If the context does not contain the necessary info, say:
"The provided context does not contain the answer."
"""
    return augmented_prompt

# ========= ÁîüÊàêAIÂõûÁ≠î =========
def generate_ai_response(query, client, search_results):
    """Âü∫‰∫éRAGÊ£ÄÁ¥¢‰∏ä‰∏ãÊñáÁîüÊàêÊúÄÁªàÂõûÁ≠î"""
    try:
        prompt = build_augmented_prompt(query, search_results)
        completion = client.chat.completions.create(
            model="gpt-35-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful assistant that uses context to answer questions accurately."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=700
        )
        answer = completion.choices[0].message.content.strip()
        confidence = round(random.uniform(0.85, 0.95), 2)
        return answer, confidence
    except Exception as e:
        st.error(f"ÁîüÊàêÂõûÁ≠îÂá∫Èîô: {e}")
        return "Error generating GPT answer.", 0

# ========= Sidebar =========
st.sidebar.title("Chat Sidebar")

api_key = st.sidebar.text_input(
    "Enter your HKUST Azure OpenAI API Key",
    type="password",
    help="Enter your valid Azure API Key to access GPT",
    value=st.session_state.get("OPENAI_API_KEY", "")
)
if api_key:
    st.session_state["OPENAI_API_KEY"] = api_key

st.sidebar.markdown("---")

# ÊµãËØïËøûÊé•
if st.sidebar.button("Test Connection", use_container_width=True):
    with st.spinner("Testing Azure + Pinecone connection..."):
        try:
            client = get_azure_client(st.session_state["OPENAI_API_KEY"])
            pinecone_index = get_pinecone_client()
            client.embeddings.create(input="Hello test", model="text-embedding-ada-002")
            pinecone_index.describe_index_stats()
            st.sidebar.success("‚úÖ Connection successful! Both Azure and Pinecone are working.")
        except Exception as e:
            st.sidebar.error(f"‚ùå Connection failed: {e}")

top_k = st.sidebar.slider("Number of documents (Top K)", 1, 10, 5)

if st.sidebar.button("New Chat", use_container_width=True):
    st.session_state["conversations"].append([])
    st.session_state["conversation_titles"].append("New Chat")
    st.session_state["active_chat_index"] = len(st.session_state["conversations"]) - 1
    st.session_state["last_processed_query"] = None
    st.rerun()

if st.sidebar.button("Clear All History", use_container_width=True):
    st.session_state["conversations"].clear()
    st.session_state["conversation_titles"].clear()
    st.session_state["active_chat_index"] = None
    st.session_state["last_processed_query"] = None
    st.rerun()

# ÂéÜÂè≤ËÆ∞ÂΩï
st.sidebar.subheader("History")
if len(st.session_state["conversations"]) == 0:
    st.sidebar.info("No history yet.")
else:
    for i, title in enumerate(st.session_state["conversation_titles"]):
        display_title = title[:20] + "..." if len(title) > 20 else title
        if i == st.session_state["active_chat_index"]:
            st.sidebar.button(f"üìç {display_title}", key=f"chat_active_{i}", disabled=True, use_container_width=True)
        else:
            if st.sidebar.button(f"üí¨ {display_title}", key=f"chat_{i}", use_container_width=True):
                st.session_state["active_chat_index"] = i
                st.session_state["last_processed_query"] = None
                st.rerun()

# ========= ‰∏ª‰ΩìÈÉ®ÂàÜ =========
st.title("Semantic Search AI Chat (Pinecone RAG)")
st.caption("Enhanced RAG pipeline: Pinecone + Azure OpenAI (HKUST Environment)")

# ÂàùÂßãÂåñËÅäÂ§©
if st.session_state["active_chat_index"] is None:
    st.session_state["conversations"].append([])
    st.session_state["conversation_titles"].append("New Chat")
    st.session_state["active_chat_index"] = 0

chat_index = st.session_state["active_chat_index"]
current_chat = st.session_state["conversations"][chat_index]
chat_title = st.session_state["conversation_titles"][chat_index]
st.subheader(f"{chat_title}")

# Â±ïÁ§∫ËÅäÂ§©ËÆ∞ÂΩï
for msg in current_chat:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# ========= Â§ÑÁêÜÊñ∞Êü•ËØ¢ =========
user_query = st.chat_input(
    placeholder="e.g., What MBA programs does HKUST offer?",
    key=f"chat_input_{chat_index}"
)

if user_query and user_query != st.session_state.get("last_processed_query"):
    if not st.session_state.get("OPENAI_API_KEY"):
        st.error("Please input Azure OpenAI API key in sidebar.")
        st.stop()

    # ÊòæÁ§∫Ê∂àÊÅØ
    with st.chat_message("user"):
        st.write(user_query)
    current_chat.append({"role": "user", "content": user_query})

    if len(current_chat) == 1:
        new_title = user_query[:30] + "..." if len(user_query) > 30 else user_query
        st.session_state["conversation_titles"][chat_index] = new_title

    with st.chat_message("assistant"):
        with st.spinner("Performing RAG: embedding ‚Üí pinecone search ‚Üí GPT reasoning..."):
            try:
                azure_client = get_azure_client(st.session_state["OPENAI_API_KEY"])
                matches, qv, dim = semantic_search(user_query, azure_client, top_k=top_k)

                answer, conf = generate_ai_response(user_query, azure_client, matches)

                answer_text = f"**Answer:** {answer}\n\n"
                answer_text += "---\n"
                answer_text += f"**Semantic Search Info:**\n- Embedding Dimension: {dim}\n- Documents Retrieved: {len(matches)}\n- Confidence: {conf}\n\n"
                if matches:
                    answer_text += "**Top Documents:**\n"
                    for i, m in enumerate(matches, 1):
                        answer_text += f"{i}. {m['text'][:180]}... (score={m['score']:.3f})\n"

                st.write(answer_text)
                current_chat.append({"role": "assistant", "content": answer_text})
                st.session_state["last_processed_query"] = user_query

            except Exception as e:
                err_msg = f"‚ùå Error: {str(e)}"
                st.error(err_msg)
                current_chat.append({"role": "assistant", "content": err_msg})
                st.session_state["last_processed_query"] = user_query

# ========= Â±ïÁ§∫‰ø°ÊÅØÈù¢Êùø =========
with st.expander("System Information"):
    st.write(f"**Active Chat:** {chat_title}")
    st.write(f"**Total Conversations:** {len(st.session_state['conversations'])}")
    st.write(f"**Messages in Current Chat:** {len(current_chat)}")
    st.write(f"**Embedding Index:** `{PINECONE_INDEX_NAME}` (namespace: `{PINECONE_NAMESPACE}`)")
    st.write(f"**OpenAI Azure Endpoint:** https://hkust.azure-api.net")
